plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
model_majority$coefficients
Z %*% model_majority$coefficients
test_fitted
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/performance.r", echo=TRUE)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/data_screening.r", echo=TRUE)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/performance.r", echo=TRUE)
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
#create ROC-curves for Raykar model + plot on training data
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot on training data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
Z <- as.matrix(data_test[,-10])
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1, main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'red', lty = 3)
#create ROC-curves for Raykar model + plot on testing data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/raykar_binary_classification.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
library(MESS)
library(MESS)
auc(1-speci, sensi)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
c <- sum(log((1-raykar_out$alpha)/raykar_out$beta))
logits <- log(raykar_out$alpha/(1-raykar_out$alpha)) + log(raykar_out$beta/(1-raykar_out$beta))
Ann_test %*% logits
logits %*% Ann_test
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
ground_truth_test <- data_test$Diagnosis
#create ROC-curves for Raykar model + plot on training data
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red) on training data",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Logistic model + plot on training data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
Z <- as.matrix(data_test[,-10])
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth_test)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth_test)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1, main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red) on test data",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'red', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Raykar model + plot on testing data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
c <- sum(log((1-raykar_out$alpha)/raykar_out$beta))
logits <- log(raykar_out$alpha/(1-raykar_out$alpha)) + log(raykar_out$beta/(1-raykar_out$beta))
logits <- logits %*% Ann_test
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w + c + logits), thresh = t[i]), ground_truth_test)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w + c + logits), thresh = t[i]), ground_truth_test)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
auc(1-speci, sensi)
#load data, we work with R = 3 simulated erroneous annotators, 90/10 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = floor(0.9 * length(data$Diagnosis)),
replace = FALSE)
data_test <- data[-inds,]
data <- data[inds,]
R <- 3
options(warn = -1)
#prepare data for ground truth logistic regression, fit logistic regression and display predictions
data_ground_truth <- data[,-c(1, 12, 13, 14)]
model_ground_truth <- glm(Diagnosis ~ . - 1, family = binomial, data = data_ground_truth)
as.numeric(model_ground_truth$fitted.values > 0.5)
#prepare data for majority vote logistic regression, fit logistic regression and display predictions
Ann <- as.matrix(t(cbind(data$Diagnosis1,data$Diagnosis2,data$Diagnosis3)))
Diagnosis_majority <- colSums(Ann) / R
data_majority <- data[,-c(1, 11, 12, 13, 14)]
data_majority$DiagnosisMajority <- Diagnosis_majority
model_majority <- glm(DiagnosisMajority ~ . - 1, family = binomial, data = data_majority)
as.numeric(model_majority$fitted.values > 0.5)
w_init_log <- as.vector(model_majority$coefficients)
colnames(w_init_log) <- NULL
options(warn = 0)
#eyeball misclassification error
sum(data$Diagnosis != as.numeric(model_ground_truth$fitted.values > 0.5))
sum(data$Diagnosis != as.numeric(model_majority$fitted.values > 0.5))
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
ground_truth_test <- data_test$Diagnosis
#create ROC-curves for Raykar model + plot on training data
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red) on training data",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Logistic model + plot on training data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
Z <- as.matrix(data_test[,-10])
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth_test)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth_test)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1, main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red) on test data",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'red', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Raykar model + plot on testing data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
c <- sum(log((1-raykar_out$alpha)/raykar_out$beta))
logits <- log(raykar_out$alpha/(1-raykar_out$alpha)) + log(raykar_out$beta/(1-raykar_out$beta))
logits <- logits %*% Ann_test
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w + c + logits), thresh = t[i]), ground_truth_test)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w + c + logits), thresh = t[i]), ground_truth_test)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
auc(1-speci, sensi)
Z %*% raykar_out$w
logits <- as.vector(logits %*% Ann_test)
logits <- log(raykar_out$alpha/(1-raykar_out$alpha)) + log(raykar_out$beta/(1-raykar_out$beta))
logits <- as.vector(logits %*% Ann_test)
sigmoid(Z %*% raykar_out$w + c + logits)
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
ground_truth_test <- data_test$Diagnosis
#create ROC-curves for Raykar model + plot on training data
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red) on training data",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Logistic model + plot on training data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
Z <- as.matrix(data_test[,-10])
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth_test)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth_test)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1, main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red) on test data",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'red', lty = 3)
auc(1-speci, sensi)
#create ROC-curves for Raykar model + plot on testing data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
c <- sum(log((1-raykar_out$alpha)/raykar_out$beta))
logits <- log(raykar_out$alpha/(1-raykar_out$alpha)) + log(raykar_out$beta/(1-raykar_out$beta))
logits <- as.vector(logits %*% Ann_test)
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w + logits + c), thresh = t[i]), ground_truth_test)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w + logits + c), thresh = t[i]), ground_truth_test)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
auc(1-speci, sensi)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/performance.r', echo=TRUE)
pos <- c(sensitivity(classifier(raykar_out$mu), ground_truth), 1-sensitivity(classifier(raykar_out$mu), ground_truth)) * sum(ground_truth == 1)
neg <- c(1-specificity(classifier(raykar_out$mu), ground_truth), specificity(classifier(raykar_out$mu), ground_truth)) * sum(ground_truth == 0)
cmat <- matrix(c(pos,neg), 2)
print("Confusion Matrix Rayar (train):")
print(cmat)
pos <- c(sensitivity(classifier(model_majority$fitted.values), ground_truth), 1-sensitivity(classifier(model_majority$fitted.values), ground_truth)) * sum(ground_truth == 1)
neg <- c(1-specificity(classifier(model_majority$fitted.values), ground_truth), specificity(classifier(model_majority$fitted.values), ground_truth)) * sum(ground_truth == 0)
cmat <- matrix(c(pos,neg), 2)
print("Confusion Matrix Rayar (train):")
print(cmat)
pos <- c(sensitivity(classifier(test_fitted), ground_truth_test), 1-sensitivity(classifier(test_fitted), ground_truth_test)) * sum(ground_truth == 1)
neg <- c(1-specificity(classifier(test_fitted), ground_truth_test), specificity(classifier(test_fitted), ground_truth_test)) * sum(ground_truth == 0)
cmat <- matrix(c(pos,neg), 2)
print("Confusion Matrix Logistic (test):")
print(cmat)
pos <- c(sensitivity(classifier(test_fitted), ground_truth_test), 1-sensitivity(classifier(test_fitted), ground_truth_test)) * sum(ground_truth_test == 1)
neg <- c(1-specificity(classifier(test_fitted), ground_truth_test), specificity(classifier(test_fitted), ground_truth_test)) * sum(ground_truth_test == 0)
cmat <- matrix(c(pos,neg), 2)
print("Confusion Matrix Logistic (test):")
print(cmat)
pos <- c(sensitivity(classifier(sigmoid(Z %*% raykar_out$w + logits + c)), ground_truth_test), 1-sensitivity(classifier(sigmoid(Z %*% raykar_out$w + logits + c)), ground_truth_test)) * sum(ground_truth_test == 1)
neg <- c(1-specificity(classifier(sigmoid(Z %*% raykar_out$w + logits + c)), ground_truth_test), specificity(classifier(sigmoid(Z %*% raykar_out$w + logits + c)), ground_truth_test)) * sum(ground_truth_test == 0)
cmat <- matrix(c(pos,neg), 2)
print("Confusion Matrix Raykar (test):")
print(cmat)
source("performance.r")
source("performance.r")
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source("performance.r")
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source("performance.r")
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/SML_LFC_Project/run.r', echo=TRUE)
