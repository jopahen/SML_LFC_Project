sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression (red)")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
#create ROC-curves for Logistic model + plot
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
#create ROC-curves for Raykar model + plot
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
source('E:/Studium/09_WS2122/SML_Project/data_screening.r', echo=TRUE)
source('E:/Studium/09_WS2122/SML_Project/performance.r', echo=TRUE)
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/performance.r", echo=TRUE)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/data_screening.r", echo=TRUE)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/raykar_binary_classification_functions.r", echo=TRUE)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/performance.r", echo=TRUE)
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
#create ROC-curves for Raykar model + plot
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/data_screening.r", echo=TRUE)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/performance.r", echo=TRUE)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/data_screening.r", echo=TRUE)
source("D:/Studium/11_WS2122/StatisticalMachineLearning/SML_LFC_Project/performance.r", echo=TRUE)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/performance.r", echo=TRUE)
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = 0.8 * length(data$Diagnosis))
data <- data[,inds]
data_test <- data[,-inds]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = 0.8 * length(data$Diagnosis))
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = 0.8 * length(data$Diagnosis))
data <- data[inds,]
data_test <- data[-inds,]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = 0.8 * length(data$Diagnosis))
data <- data[inds,]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = 0.8 * length(data$Diagnosis))
data <- data[inds,]
data_test <- data[-inds,]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = 0.8 * length(data$Diagnosis))
data <- data[inds,]
data_test <- data[-inds,]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = ceil(0.8 * length(data$Diagnosis)))
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = floor(0.8 * length(data$Diagnosis)))
data <- data[inds,]
data_test <- data[-inds,]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = floor(0.8 * length(data$Diagnosis)))
data_test <- data[-inds,]
data <- data[inds,]
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = floor(0.8 * length(data$Diagnosis)),
replace = FALSE)
data_test <- data[-inds,]
data <- data[inds,]
R <- 3
options(warn = -1)
#prepare data for ground truth logistic regression, fit logistic regression and display predictions
data_ground_truth <- data[,-c(1, 12, 13, 14)]
model_ground_truth <- glm(Diagnosis ~ . - 1, family = binomial, data = data_ground_truth)
as.numeric(model_ground_truth$fitted.values > 0.5)
#prepare data for majority vote logistic regression, fit logistic regression and display predictions
Ann <- as.matrix(t(cbind(data$Diagnosis1,data$Diagnosis2,data$Diagnosis3)))
Diagnosis_majority <- colSums(Ann) / R
data_majority <- data[,-c(1, 11, 12, 13, 14)]
data_majority$DiagnosisMajority <- Diagnosis_majority
model_majority <- glm(DiagnosisMajority ~ . - 1, family = binomial, data = data_majority)
as.numeric(model_majority$fitted.values > 0.5)
w_init_log <- as.vector(model_majority$coefficients)
colnames(w_init_log) <- NULL
options(warn = 0)
#eyeball misclassification error
sum(data$Diagnosis != as.numeric(model_ground_truth$fitted.values > 0.5))
sum(data$Diagnosis != as.numeric(model_majority$fitted.values > 0.5))
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/performance.r", echo=TRUE)
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
#create ROC-curves for Raykar model + plot
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
predict(model_majority, newdata = data_test)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
predict(model_majority, newdata = data_test)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
test_fitted <- predict(model_majority, newdata = data_test)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
test_fitted <- predict(model_majority, newdata = data_test)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
#load data, we work with R = 3 simulated erroneous annotators, 80/20 train/test split
#data = training data, data_test = testing data
data <- read.csv("Datasets/BreastCancerWisconsinAnnotated03.csv")[,-1]
inds <- sample(1:length(data$Diagnosis), size = floor(0.8 * length(data$Diagnosis)),
replace = FALSE)
data_test <- data[-inds,]
data <- data[inds,]
R <- 3
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
test_fitted <- predict(model_majority, newdata = data_test)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
t <- seq(-2,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/logistic_regression_binary_classification.r", echo=TRUE)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
test_fitted <- predict(model_majority, newdata = data_test)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
raykar_out$w
Z <- as.matrix(data_test[,-10])
Z %*% raykar_out$w
sigmoid(Z %*% raykar_out$w)
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
t <- seq(-3,2,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
model_majority$coefficients
Z %*% model_majority$coefficients
test_fitted
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1)
lines(1-speci, sensi, col = 'red', lty = 3)
Z <- as.matrix(data_test[,-10])
t <- seq(-1,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/performance.r", echo=TRUE)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/data_screening.r", echo=TRUE)
source("C:/Studium/WS2122/StatisticalML/Project/SML_LFC_Project/performance.r", echo=TRUE)
#function to evaluate classifier based on different model fitted values and thresholds
classifier <- function(fitted_vals, thresh = 0.5){
return(as.numeric(fitted_vals > thresh))
}
#functions to calculate specificities/sensitivities
sensitivity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 1])
num <- length(classified_vals[(classified_vals == 1) & (ground_truth == 1)])
return(num/den)
}
specificity <- function(classified_vals, ground_truth){
den <- length(ground_truth[ground_truth == 0])
num <- length(classified_vals[(classified_vals == 0) & (ground_truth == 0)])
return(num/den)
}
ground_truth <- data_ground_truth$Diagnosis
#create ROC-curves for Raykar model + plot on training data
par(pty = "s")
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(raykar_out$mu, thresh = t[i]), ground_truth)
}
plot(1-speci, sensi, pch = 20, col = 'blue', asp = 1,
main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'blue', lty = 3)
#create ROC-curves for Logistic model + plot on training data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(model_majority$fitted.values, thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'red', pch = 4)
lines(1-speci, sensi, col = 'red', lty = 3)
#create ROC-curves for Logistic model + plot on testing data
Ann_test <- as.matrix(t(cbind(data_test$Diagnosis1,data_test$Diagnosis2,data_test$Diagnosis3)))
Diagnosis_majority <- colSums(Ann_test) / R
data_test <- data_test[,-c(1, 11, 12, 13, 14)]
data_test$DiagnosisMajority <- Diagnosis_majority
Z <- as.matrix(data_test[,-10])
test_fitted <- sigmoid(Z %*% model_majority$coefficients)
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(test_fitted, thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(test_fitted, thresh = t[i]), ground_truth)
}
par(pty = "s")
plot(1-speci, sensi, col = 'red', pch = 4, asp = 1, main = "ROC curve for Raykar (blue) & Logistic regression with majority voting (red)",
xlab = "FPR = 1 - Specificity", ylab = "Sensitivity")
lines(1-speci, sensi, col = 'red', lty = 3)
#create ROC-curves for Raykar model + plot on testing data
t <- seq(0,1,0.02)
sensi <- numeric(length(t))
speci <- numeric(length(t))
for(i in 1:length(t)){
sensi[i] <- sensitivity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
speci[i] <- specificity(classifier(sigmoid(Z %*% raykar_out$w), thresh = t[i]), ground_truth)
}
points(1-speci, sensi, col = 'blue', pch = 4)
lines(1-speci, sensi, col = 'blue', lty = 3)
